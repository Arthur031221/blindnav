# app/bus_vision.py

import os
import cv2
import time
import threading
import re
from typing import Any, Dict, Optional

import numpy as np
from ultralytics import YOLO
import easyocr

# ---------------- è¨­å®šå€ ----------------

# YOLO æ¬Šé‡ï¼šå¦‚æœä½ æœ‰è‡ªå·±çš„ bus æ¨¡å‹ï¼Œå¯ä»¥æ”¹é€™è£¡ï¼Œä¾‹å¦‚ "bus_best.pt"
YOLO_WEIGHTS = "yolov8n.pt"

# YOLO conf é–€æª»ï¼šå…ˆè¨­ä½ä¸€é»ï¼Œç¢ºä¿æŠ“å¾—åˆ°æ±è¥¿
# é™ä½é–€æª»ä»¥å¢åŠ æ•æ„Ÿåº¦ï¼Œæ›´å®¹æ˜“åµæ¸¬åˆ°å…¬è»Š
YOLO_CONF = 0.05  # é™ä½åˆ° 0.05ï¼Œå¤§å¹…å¢åŠ æ•æ„Ÿåº¦ï¼Œç¢ºä¿èƒ½åµæ¸¬åˆ°ç‰©é«”

# å¹€ç‡æ§åˆ¶ï¼šæ¯å¹¾å¼µ frame åšä¸€æ¬¡ YOLO+OCR
_DETECT_INTERVAL = 3  # æ¯ 3 å¼µåšä¸€æ¬¡åµæ¸¬ï¼Œæ¸›å°‘é‹ç®—é‡ä»¥æå‡å½±ç‰‡æµæš¢åº¦

# è¦–è¨Šæµ FPS é™åˆ¶ï¼ˆé¿å…éåº¦è™•ç†å°è‡´å¡é “ï¼‰
# å½±ç‰‡æ¨¡å¼ä¸‹ä½¿ç”¨è¼ƒæ…¢çš„ FPSï¼Œè®“ YOLO æœ‰è¶³å¤ æ™‚é–“è™•ç†
_TARGET_FPS = 30  # æ¢å¾©åˆ° 30 FPSï¼Œè®“å½±ç‰‡çœ‹èµ·ä¾†æµæš¢
_FRAME_INTERVAL = 1.0 / _TARGET_FPS  # æ¯å¹€é–“éš”æ™‚é–“ï¼ˆç§’ï¼‰

# å½±ç‰‡æ’­æ”¾é€Ÿåº¦æ§åˆ¶ï¼ˆå›ºå®šç‚ºæ­£å¸¸é€Ÿåº¦ï¼Œä¸å—æ¨¡æ“¬é€Ÿåº¦å½±éŸ¿ï¼‰
_video_fps: Optional[float] = None  # å½±ç‰‡çš„å¯¦éš› FPS
_video_frame_interval: Optional[float] = None  # æ ¹æ“šå½±ç‰‡ FPS è¨ˆç®—çš„ frame interval
_last_video_frame: Optional[np.ndarray] = None  # ç·©å­˜æœ€å¾Œä¸€å¹€ï¼Œé¿å…å¾ªç’°æ’­æ”¾æ™‚é–ƒçˆ
_video_start_sec: float = 0.0  # å½±ç‰‡é–‹å§‹æ™‚é–“ï¼ˆç§’ï¼‰
_video_end_sec: Optional[float] = None  # å½±ç‰‡çµæŸæ™‚é–“ï¼ˆç§’ï¼‰

# Debugï¼šæ˜¯å¦æŠŠ bus LED ROI å­˜æˆåœ–ç‰‡
DEBUG_SAVE_ROI = True
_DEBUG_SAVE_LIMIT = 200

# ---------------- è¼¸å…¥ä¾†æºè¨­å®š ----------------
# è¨­å®šè¼¸å…¥ä¾†æºæ¨¡å¼ï¼š
#   "realtime" - ä½¿ç”¨å³æ™‚å½±åƒï¼ˆæ‰‹æ©Ÿæ”å½±æ©Ÿï¼‰
#   "video"    - ä½¿ç”¨å½±ç‰‡æª”æ¡ˆ
INPUT_MODE = "video"  # æ”¹é€™è£¡é¸æ“‡æ¨¡å¼ï¼š"realtime" æˆ– "video"

# å½±ç‰‡æª”æ¡ˆè·¯å¾‘ï¼ˆåƒ…åœ¨ INPUT_MODE = "video" æ™‚ä½¿ç”¨ï¼‰
# ç¯„ä¾‹è·¯å¾‘ï¼š
#   Windows: "D:/videos/bus_video.mp4" æˆ– r"D:\videos\bus_video.mp4"
#   Linux/Mac: "/home/user/videos/bus_video.mp4"
VIDEO_FILE_PATH = r"D:\blindnav_local\backend\videos\IMG_3361.MOV"  # æ”¹é€™è£¡è¨­å®šå½±ç‰‡è·¯å¾‘

# ---------------- æ¨¡å‹åˆå§‹åŒ– ----------------

yolo_model = None
_yolo_error_count = 0
_yolo_last_error_time = 0

def _init_yolo_model():
    """åˆå§‹åŒ–æˆ–é‡æ–°åˆå§‹åŒ– YOLO æ¨¡å‹"""
    global yolo_model
    try:
        print(f"[bus_vision] Loading YOLO model from {YOLO_WEIGHTS} ...")
        yolo_model = YOLO(YOLO_WEIGHTS)
        
        # å˜—è©¦ä½¿ç”¨ GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            import torch
            if torch.cuda.is_available():
                device = "cuda"
                print(f"[bus_vision] YOLO model will use GPU (CUDA device: {torch.cuda.get_device_name(0)})")
            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                device = "mps"  # Apple Silicon GPU
                print("[bus_vision] YOLO model will use GPU (Apple Silicon MPS)")
            else:
                device = "cpu"
                print("[bus_vision] YOLO model will use CPU (GPU not available)")
            
            # å°‡æ¨¡å‹ç§»åˆ°æŒ‡å®šè¨­å‚™ï¼ˆYOLO æœƒè‡ªå‹•è™•ç†ï¼Œä½†æˆ‘å€‘å¯ä»¥æ˜ç¢ºæŒ‡å®šï¼‰
            # YOLO åœ¨æ¨ç†æ™‚æœƒè‡ªå‹•ä½¿ç”¨å¯ç”¨çš„è¨­å‚™
        except ImportError:
            print("[bus_vision] PyTorch not available, using default device")
            device = "cpu"
        
        print("[bus_vision] YOLO model loaded.")
        return True
    except Exception as e:
        print(f"[bus_vision] Failed to load YOLO model: {e}")
        yolo_model = None
        return False

# åˆå§‹åŒ–æ¨¡å‹
_init_yolo_model()

print("[bus_vision] Initializing EasyOCR (en only)...")
# å˜—è©¦ä½¿ç”¨ GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰ï¼Œä½†è€ƒæ…®åˆ° GPU è¨˜æ†¶é«”é™åˆ¶ï¼ˆ3GBï¼‰ï¼Œå„ªå…ˆä½¿ç”¨ CPU
# å¦‚æœ GPU è¨˜æ†¶é«”ä¸è¶³ï¼ŒEasyOCR æœƒè‡ªå‹•åˆ‡æ›åˆ° CPU
try:
    import torch
    if torch.cuda.is_available():
        # æª¢æŸ¥ GPU è¨˜æ†¶é«”å¤§å°
        gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        print(f"[bus_vision] GPU è¨˜æ†¶é«”ç¸½é‡: {gpu_memory_gb:.2f} GB")
        
        # å¦‚æœ GPU è¨˜æ†¶é«”å°æ–¼ 4GBï¼Œå„ªå…ˆä½¿ç”¨ CPU ä»¥é¿å… OOM
        if gpu_memory_gb < 4.0:
            use_gpu = False
            print(f"[bus_vision] GPU è¨˜æ†¶é«”è¼ƒå°ï¼ˆ{gpu_memory_gb:.2f} GBï¼‰ï¼ŒEasyOCR å°‡ä½¿ç”¨ CPU ä»¥é¿å…è¨˜æ†¶é«”ä¸è¶³")
        else:
            use_gpu = True
            print(f"[bus_vision] EasyOCR will use GPU (CUDA device: {torch.cuda.get_device_name(0)})")
    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        use_gpu = True  # EasyOCR å¯èƒ½ä¸æ”¯æ´ MPSï¼Œä½†å…ˆå˜—è©¦
        print("[bus_vision] EasyOCR will attempt to use GPU (Apple Silicon)")
    else:
        use_gpu = False
        print("[bus_vision] EasyOCR will use CPU (GPU not available)")
except ImportError:
    use_gpu = False
    print("[bus_vision] PyTorch not available, EasyOCR will use CPU")

ocr_reader = easyocr.Reader(['en'], gpu=use_gpu)
print("[bus_vision] EasyOCR ready.")

# ---------------- å…¨åŸŸç‹€æ…‹ ----------------

_cap: Optional[cv2.VideoCapture] = None
_cap_lock = threading.Lock()  # VideoCapture æ“ä½œçš„ç·šç¨‹é–
_bus_running: bool = False
_use_mobile_camera: bool = False  # æ˜¯å¦ä½¿ç”¨æ‰‹æ©Ÿé¡é ­
_use_video_file: bool = False  # æ˜¯å¦ä½¿ç”¨å½±ç‰‡æª”æ¡ˆ
_video_file_path: Optional[str] = None  # å½±ç‰‡æª”æ¡ˆè·¯å¾‘
_mobile_frame_queue: Optional[list] = None  # æ‰‹æ©Ÿè¦–è¨Šæµ queue
_mobile_frame_lock = threading.Lock()

last_bus_status: Dict = {
    "bus_number": None,
    "raw_text": None,
    "confidence": 0.0,
    "last_seen_ts": None,
}

# è¨˜éŒ„æœ€è¿‘5æ¬¡åµæ¸¬çµæœï¼ˆç”¨æ–¼è¨ˆç®—ä¿¡å¿ƒåº¦ï¼‰
_recent_detections: list = []  # æ ¼å¼: [{"bus_number": "123", "timestamp": 1234567890}, ...]
_max_recent_detections = 5
_detection_lock = threading.Lock()

_status_lock = threading.Lock()
_last_annotated_frame: Optional[np.ndarray] = None
_debug_save_count = 0


# ---------------- æ”å½±æ©Ÿ ----------------

def _open_camera():
    """é–‹å•Ÿæ”å½±æ©Ÿæˆ–å½±ç‰‡æª”æ¡ˆï¼ˆåªé–‹ä¸€æ¬¡ï¼Œåƒ…åœ¨éæ‰‹æ©Ÿæ¨¡å¼æ™‚ä½¿ç”¨ï¼‰"""
    global _cap, _use_video_file, _video_file_path
    if _use_mobile_camera:
        return  # ä½¿ç”¨æ‰‹æ©Ÿé¡é ­æ™‚ä¸éœ€è¦é–‹å•Ÿé›»è…¦æ”å½±æ©Ÿæˆ–å½±ç‰‡æª”æ¡ˆ
    
    with _cap_lock:
        if _cap is not None:
            return
        
        if _use_video_file and _video_file_path:
            # é–‹å•Ÿå½±ç‰‡æª”æ¡ˆ
            if not os.path.exists(_video_file_path):
                print(f"[bus_vision] å½±ç‰‡æª”æ¡ˆä¸å­˜åœ¨: {_video_file_path}")
                return
            try:
                cap = cv2.VideoCapture(_video_file_path)
                if not cap.isOpened():
                    print(f"[bus_vision] ç„¡æ³•é–‹å•Ÿå½±ç‰‡æª”æ¡ˆ: {_video_file_path}")
                    return
                # æ¸¬è©¦è®€å–ç¬¬ä¸€å¹€ä»¥ç¢ºèªå½±ç‰‡å¯æ­£å¸¸è®€å–
                ret, test_frame = cap.read()
                if not ret:
                    cap.release()
                    print(f"[bus_vision] ç„¡æ³•è®€å–å½±ç‰‡å…§å®¹: {_video_file_path}")
                    return
                # é‡ç½®åˆ°ç¬¬ä¸€å¹€
                cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                
                # ç²å–å½±ç‰‡çš„å¯¦éš› FPSï¼ˆç”¨æ–¼æ§åˆ¶æ’­æ”¾é€Ÿåº¦ï¼‰
                global _video_fps, _video_frame_interval, _last_video_frame
                _video_fps = cap.get(cv2.CAP_PROP_FPS)
                if _video_fps and _video_fps > 0:
                    _video_frame_interval = 1.0 / _video_fps
                    print(f"[bus_vision] å½±ç‰‡ FPS: {_video_fps:.2f}, Frame interval: {_video_frame_interval:.4f}ç§’")
                else:
                    # å¦‚æœç„¡æ³•ç²å– FPSï¼Œä½¿ç”¨é è¨­å€¼
                    _video_fps = 30.0
                    _video_frame_interval = 1.0 / 30.0
                    print(f"[bus_vision] ç„¡æ³•ç²å–å½±ç‰‡ FPSï¼Œä½¿ç”¨é è¨­å€¼ 30 FPS")
                
                # è¨­å®šèµ·å§‹æ™‚é–“
                if _video_start_sec > 0:
                    print(f"[bus_vision] è¨­å®šå½±ç‰‡èµ·å§‹æ™‚é–“: {_video_start_sec} ç§’")
                    cap.set(cv2.CAP_PROP_POS_MSEC, _video_start_sec * 1000)

                # ç·©å­˜ç¬¬ä¸€å¹€ï¼ˆç”¨æ–¼å¾ªç’°æ’­æ”¾æ™‚é¿å…é–ƒçˆï¼‰
                ret, test_frame = cap.read()
                if ret:
                    _last_video_frame = test_frame.copy()
                    # å¦‚æœè®€å–äº†ï¼Œè¦é€€å›å»ï¼Œæˆ–è€…é€™è£¡å°±ç•¶ä½œé è®€
                    # ä½†å› ç‚ºä¸‹é¢è¿´åœˆæœƒè®€ï¼Œé€™è£¡ reset ä½ç½®æ¯”è¼ƒä¿éšªï¼Œé™¤éæ˜¯å‰›å¥½ start_sec
                    cap.set(cv2.CAP_PROP_POS_MSEC, _video_start_sec * 1000)
                
                _cap = cap
                print(f"[bus_vision] å½±ç‰‡æª”æ¡ˆå·²é–‹å•Ÿ: {_video_file_path}")
            except Exception as e:
                print(f"[bus_vision] é–‹å•Ÿå½±ç‰‡æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                if '_cap' in locals() and cap is not None:
                    try:
                        cap.release()
                    except:
                        pass
                return
        else:
            # é–‹å•Ÿé›»è…¦æ”å½±æ©Ÿ
            cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            _cap = cap
            print("[bus_vision] Camera opened.")


def _close_camera():
    global _cap
    with _cap_lock:
        if _cap is not None:
            _cap.release()
            _cap = None
            print("[bus_vision] Camera closed.")


def receive_mobile_frame(frame_bytes: bytes):
    """æ¥æ”¶ä¾†è‡ªæ‰‹æ©Ÿçš„è¦–è¨Š frame"""
    global _mobile_frame_queue
    try:
        # æª¢æŸ¥ NumPy æ˜¯å¦å¯ç”¨
        try:
            _ = np.array([1])
        except Exception:
            # NumPy ä¸å¯ç”¨ï¼Œè·³éæ­¤ frame
            return False
        
        # å°‡ bytes è½‰æ›ç‚º numpy array
        nparr = np.frombuffer(frame_bytes, np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if frame is None:
            return False
        
        with _mobile_frame_lock:
            if _mobile_frame_queue is None:
                _mobile_frame_queue = []
            # åªä¿ç•™æœ€æ–°çš„ frameï¼ˆé¿å… queue éé•·ï¼Œæ¸›å°‘è¨˜æ†¶é«”ä½¿ç”¨ï¼‰
            # å®Œå…¨æ¸…ç©ºèˆŠçš„ï¼Œåªä¿ç•™æœ€æ–°çš„ä¸€å¼µ
            _mobile_frame_queue.clear()
            _mobile_frame_queue.append(frame)
        return True
    except RuntimeError as e:
        if "Numpy is not available" in str(e) or "numpy" in str(e).lower():
            # NumPy éŒ¯èª¤ï¼Œéœé»˜è™•ç†ï¼ˆé¿å…åˆ·å±ï¼‰
            return False
        print(f"[bus_vision] æ¥æ”¶æ‰‹æ©Ÿ frame RuntimeError: {e}")
        return False
    except Exception as e:
        print(f"[bus_vision] æ¥æ”¶æ‰‹æ©Ÿ frame éŒ¯èª¤: {e}")
        return False


def _get_frame():
    """å–å¾— frameï¼ˆå¾é›»è…¦æ”å½±æ©Ÿã€å½±ç‰‡æª”æ¡ˆæˆ–æ‰‹æ©Ÿè¦–è¨Šæµï¼‰"""
    global _cap, _mobile_frame_queue, _use_mobile_camera, _use_video_file
    
    if _use_mobile_camera:
        # å¾æ‰‹æ©Ÿè¦–è¨Šæµè®€å–
        with _mobile_frame_lock:
            if _mobile_frame_queue and len(_mobile_frame_queue) > 0:
                frame = _mobile_frame_queue[-1]
                # ç¢ºä¿ frame æ˜¯æœ‰æ•ˆçš„ numpy array
                if frame is not None and isinstance(frame, np.ndarray) and frame.size > 0:
                    return True, frame.copy()
        return False, None
    else:
        # å¾é›»è…¦æ”å½±æ©Ÿæˆ–å½±ç‰‡æª”æ¡ˆè®€å–ï¼ˆä½¿ç”¨ç·šç¨‹é–ä¿è­·ï¼‰
        with _cap_lock:
            if _cap is None:
                return False, None
            
            try:
                # æª¢æŸ¥æ˜¯å¦è¶…éçµæŸæ™‚é–“
                if _use_video_file and _video_end_sec is not None:
                    current_pos = _cap.get(cv2.CAP_PROP_POS_MSEC)
                    if current_pos > _video_end_sec * 1000:
                        # è¶…éçµæŸæ™‚é–“ï¼Œé‡ç½®åˆ°èµ·å§‹æ™‚é–“
                        # print(f"[bus_vision] å½±ç‰‡è¶…éçµæŸæ™‚é–“ ({_video_end_sec}s)ï¼Œé‡ç½®åˆ°èµ·å§‹æ™‚é–“ ({_video_start_sec}s)")
                        _cap.set(cv2.CAP_PROP_POS_MSEC, _video_start_sec * 1000)

                ret, frame = _cap.read()
            except Exception as e:
                print(f"[bus_vision] è®€å– frame æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                # å˜—è©¦é‡æ–°é–‹å•Ÿå½±ç‰‡æª”æ¡ˆ
                if _use_video_file and _video_file_path:
                    try:
                        _cap.release()
                        _cap = cv2.VideoCapture(_video_file_path)
                        if _cap.isOpened():
                            print(f"[bus_vision] å·²é‡æ–°é–‹å•Ÿå½±ç‰‡æª”æ¡ˆ")
                            ret, frame = _cap.read()
                        else:
                            print(f"[bus_vision] ç„¡æ³•é‡æ–°é–‹å•Ÿå½±ç‰‡æª”æ¡ˆ")
                            return False, None
                    except Exception as e2:
                        print(f"[bus_vision] é‡æ–°é–‹å•Ÿå½±ç‰‡æª”æ¡ˆå¤±æ•—: {e2}")
                        return False, None
                else:
                    return False, None
            
            # å¦‚æœæ˜¯å½±ç‰‡æª”æ¡ˆæ¨¡å¼ä¸”è®€å–å¤±æ•—ï¼ˆå½±ç‰‡çµæŸï¼‰ï¼Œå¯ä»¥é¸æ“‡å¾ªç’°æ’­æ”¾æˆ–åœæ­¢
            if not ret and _use_video_file:
                global _last_video_frame
                # å¦‚æœæœ‰ç·©å­˜çš„æœ€å¾Œä¸€å¹€ï¼Œå…ˆä½¿ç”¨å®ƒï¼ˆé¿å…é–ƒçˆï¼‰
                if _last_video_frame is not None:
                    # ä½¿ç”¨ç·©å­˜çš„å¹€ï¼ŒåŒæ™‚åœ¨èƒŒæ™¯é‡ç½®å½±ç‰‡
                    try:
                        _cap.set(cv2.CAP_PROP_POS_MSEC, _video_start_sec * 1000)
                        # å˜—è©¦è®€å–ç¬¬ä¸€å¹€
                        ret_new, frame_new = _cap.read()
                        if ret_new and frame_new is not None:
                            # æˆåŠŸé‡ç½®ï¼Œæ›´æ–°ç·©å­˜
                            _last_video_frame = frame_new.copy()
                            return True, frame_new.copy()
                        else:
                            # é‡ç½®å¤±æ•—ï¼Œä½¿ç”¨ç·©å­˜çš„å¹€
                            return True, _last_video_frame.copy()
                    except Exception as e:
                        # é‡ç½®æ™‚å‡ºéŒ¯ï¼Œä½¿ç”¨ç·©å­˜çš„å¹€
                        if _last_video_frame is not None:
                            return True, _last_video_frame.copy()
                        print(f"[bus_vision] å½±ç‰‡å¾ªç’°æ’­æ”¾æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                else:
                    # æ²’æœ‰ç·©å­˜ï¼Œå˜—è©¦é‡æ–°é–‹å§‹æ’­æ”¾
                    try:
                        _cap.set(cv2.CAP_PROP_POS_MSEC, _video_start_sec * 1000)
                        ret, frame = _cap.read()
                        if ret and frame is not None:
                            _last_video_frame = frame.copy()
                            return True, frame.copy()
                        else:
                            # å¦‚æœé‚„æ˜¯å¤±æ•—ï¼Œå˜—è©¦é‡æ–°é–‹å•Ÿ
                            _cap.release()
                            _cap = cv2.VideoCapture(_video_file_path)
                            if _cap.isOpened():
                                ret, frame = _cap.read()
                                if ret and frame is not None:
                                    _last_video_frame = frame.copy()
                                    return True, frame.copy()
                    except Exception as e:
                        print(f"[bus_vision] å½±ç‰‡å¾ªç’°æ’­æ”¾æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                        # å˜—è©¦é‡æ–°é–‹å•Ÿå½±ç‰‡æª”æ¡ˆ
                        try:
                            if _cap is not None:
                                _cap.release()
                            _cap = cv2.VideoCapture(_video_file_path)
                            if _cap.isOpened():
                                print(f"[bus_vision] å·²é‡æ–°é–‹å•Ÿå½±ç‰‡æª”æ¡ˆï¼ˆå¾ªç’°æ’­æ”¾å¤±æ•—å¾Œï¼‰")
                                ret, frame = _cap.read()
                                if ret and frame is not None:
                                    _last_video_frame = frame.copy()
                                    return True, frame.copy()
                        except Exception as e2:
                            print(f"[bus_vision] é‡æ–°é–‹å•Ÿå½±ç‰‡æª”æ¡ˆå¤±æ•—: {e2}")
            
            if ret and frame is not None and isinstance(frame, np.ndarray):
                # æ›´æ–°ç·©å­˜ï¼ˆåƒ…åœ¨å½±ç‰‡æ¨¡å¼ä¸‹ï¼‰
                if _use_video_file:
                    _last_video_frame = frame.copy()
                return True, frame.copy()  # è¤‡è£½ frame ä»¥é¿å…ç·šç¨‹å•é¡Œ
        return False, None


# ---------------- å·¥å…·å‡½å¼ ----------------

def _extract_bus_number_from_text(text: str) -> Optional[str]:
    """å¾ OCR å­—ä¸²è£¡æŠ“å¯èƒ½çš„å…¬è»Šè™Ÿç¢¼ï¼ˆåªæå–æ•¸å­—ï¼Œ1~4 ä½ï¼‰"""
    if not text:
        return None

    cleaned = text
    for ch in ["è·¯", "å…¬è»Š", "å…¬äº¤", "å·´å£«", "ç·š"]:
        cleaned = cleaned.replace(ch, " ")

    # åªæå–æ•¸å­—ï¼Œä¸è¦è‹±æ–‡
    cleaned = re.sub(r"[^0-9\s]", " ", cleaned)
    candidates = re.findall(r"[0-9]{1,4}", cleaned)
    if not candidates:
        return None

    # é¸æ“‡æœ€é•·çš„æ•¸å­—ä¸²ï¼ˆé€šå¸¸æ˜¯å®Œæ•´çš„å…¬è»Šè™Ÿç¢¼ï¼‰
    candidates.sort(key=len, reverse=True)
    return candidates[0]


def _update_bus_status(bus_number: Optional[str],
                       raw_text: Optional[str],
                       conf: float):
    """æ›´æ–° last_bus_statusï¼ˆthread-safeï¼‰ä¸¦è¨˜éŒ„åˆ°æœ€è¿‘åµæ¸¬åˆ—è¡¨ï¼ˆåªè¨˜éŒ„æœ‰æ•¸å­—çš„çµæœï¼‰"""
    global last_bus_status, _recent_detections
    current_ts = int(time.time())
    
    # åªè¨˜éŒ„æœ‰æ•¸å­—çš„çµæœï¼ˆä¸è¦è‹±æ–‡ï¼‰
    if not bus_number or not bus_number.isdigit():
        return
    
    with _status_lock:
        last_bus_status["bus_number"] = bus_number
        last_bus_status["raw_text"] = raw_text
        last_bus_status["confidence"] = float(conf)
        last_bus_status["last_seen_ts"] = current_ts
        
        # è¨˜éŒ„åˆ°æœ€è¿‘åµæ¸¬åˆ—è¡¨ï¼ˆåªè¨˜éŒ„æœ‰æ•¸å­—çš„ï¼‰
        with _detection_lock:
            _recent_detections.append({
                "bus_number": bus_number,
                "confidence": float(conf),  # ä½¿ç”¨ OCR çš„ confidence
                "timestamp": current_ts
            })
            # åªä¿ç•™æœ€è¿‘5æ¬¡æœ‰æ•¸å­—çš„åµæ¸¬çµæœ
            if len(_recent_detections) > _max_recent_detections:
                _recent_detections.pop(0)


def _save_roi_debug_image(roi_bgr: np.ndarray, candidate_no: Optional[str]):
    """æŠŠ LED ROI å­˜èµ·ä¾†ï¼Œæ”¶è³‡æ–™ç”¨"""
    global _debug_save_count
    if not DEBUG_SAVE_ROI:
        return
    if _debug_save_count >= _DEBUG_SAVE_LIMIT:
        return

    os.makedirs("debug_bus_rois", exist_ok=True)
    ts = time.strftime("%Y%m%d_%H%M%S")
    suffix = candidate_no if candidate_no else "unknown"
    filename = f"roi_{ts}_{_debug_save_count:04d}_{suffix}.png"
    path = os.path.join("debug_bus_rois", filename)
    cv2.imwrite(path, roi_bgr)
    _debug_save_count += 1
    print(f"[bus_vision] Saved ROI debug image: {path}")


def _preprocess_roi_for_ocr(roi_bgr: np.ndarray) -> np.ndarray:
    """LED å€å¡Šå‰è™•ç†ï¼šæ”¾å¤§ + è‡ªé©æ‡‰äºŒå€¼åŒ– + åç›¸ + è½‰ 3-channel"""
    if roi_bgr is None or roi_bgr.size == 0:
        return roi_bgr

    h, w = roi_bgr.shape[:2]
    scale = 2.0
    roi_bgr = cv2.resize(
        roi_bgr,
        (int(w * scale), int(h * scale)),
        interpolation=cv2.INTER_CUBIC,
    )

    gray = cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2GRAY)

    thr = cv2.adaptiveThreshold(
        gray,
        255,
        cv2.ADAPTIVE_THRESH_MEAN_C,
        cv2.THRESH_BINARY,
        31,
        10,
    )

    thr = cv2.bitwise_not(thr)
    roi_rgb = cv2.cvtColor(thr, cv2.COLOR_GRAY2RGB)
    return roi_rgb


# ---------------- å–®å¼µ frame è™•ç† ----------------

def _process_frame(frame: np.ndarray) -> np.ndarray:
    """
    å°å–®ä¸€ frame è·‘ YOLO + OCRï¼Œç•«æ¡†å¾Œå›å‚³ã€‚
    ä¸¦æ›´æ–° last_bus_statusã€‚
    æ·»åŠ è¶…æ™‚ä¿è­·ä»¥é¿å…å¡æ­»ã€‚
    """
    h, w, _ = frame.shape

    # 1) YOLO åµæ¸¬
    global yolo_model, _yolo_error_count, _yolo_last_error_time
    
    # æª¢æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨
    if yolo_model is None:
        # å˜—è©¦é‡æ–°åˆå§‹åŒ–æ¨¡å‹
        if not _init_yolo_model():
            return frame
    
    try:
        # ç¢ºä¿ frame æ˜¯æœ‰æ•ˆçš„ numpy array
        if frame is None or not isinstance(frame, np.ndarray) or frame.size == 0:
            return frame
        
        # æª¢æŸ¥ NumPy æ˜¯å¦å¯ç”¨
        try:
            # ç°¡å–®æ¸¬è©¦ NumPy æ˜¯å¦æ­£å¸¸
            _ = np.array([1, 2, 3])
        except Exception as np_err:
            # NumPy ä¸å¯ç”¨ï¼Œè·³éæ­¤ frame
            _yolo_error_count += 1
            current_time = time.time()
            # æ¯ 5 ç§’åªè¼¸å‡ºä¸€æ¬¡éŒ¯èª¤ï¼Œé¿å…åˆ·å±
            if current_time - _yolo_last_error_time > 5:
                print(f"[bus_vision] NumPy not available (error count: {_yolo_error_count}), skipping frame")
                _yolo_last_error_time = current_time
            return frame
        
        # å˜—è©¦ä½¿ç”¨ GPU åŠ é€Ÿï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            import torch
            if torch.cuda.is_available():
                device = 0  # ä½¿ç”¨ç¬¬ä¸€å€‹ GPU
                # æ¸…ç† GPU å¿«å–ï¼ˆé¿å…è¨˜æ†¶é«”ç´¯ç©ï¼‰
                torch.cuda.empty_cache()
            else:
                device = "cpu"
        except:
            device = "auto"  # è®“ YOLO è‡ªå‹•é¸æ“‡
        
        # ä½¿ç”¨ YOLO æ¨¡å‹é€²è¡Œåµæ¸¬ï¼ˆç¢ºä¿æ¨¡å‹è¢«ä½¿ç”¨ï¼‰
        print(f"[bus_vision] ğŸ” é–‹å§‹ YOLO åµæ¸¬ï¼ˆconf={YOLO_CONF}, imgsz=640, device={device}ï¼‰...")
        print(f"[bus_vision] ğŸ“ Frame å°ºå¯¸: {w}x{h}")
        
        # ç¢ºä¿æ¨¡å‹ä¸ç‚º None
        if yolo_model is None:
            print(f"[bus_vision] âŒ éŒ¯èª¤ï¼šYOLO æ¨¡å‹ç‚º Noneï¼Œç„¡æ³•é€²è¡Œåµæ¸¬")
            return frame
        
        results = yolo_model(
            frame,
            imgsz=416,  # é™ä½å°ºå¯¸ä»¥ç¯€çœ GPU è¨˜æ†¶é«”ï¼ˆå¾ 640 é™åˆ° 416ï¼‰
            conf=YOLO_CONF,
            verbose=False,  # é—œé–‰ YOLO çš„ verbose è¼¸å‡ºï¼Œä½¿ç”¨æˆ‘å€‘è‡ªå·±çš„æ—¥èªŒ
            device=device,  # æ˜ç¢ºæŒ‡å®šè¨­å‚™
            half=False,  # GTX 1050 ä¸æ”¯æ´ FP16ï¼Œä½¿ç”¨ FP32
        )
        print(f"[bus_vision] âœ“ YOLO æ¨¡å‹åŸ·è¡Œå®Œæˆï¼Œçµæœé¡å‹: {type(results)}")
        
        # YOLO è™•ç†å¾Œç«‹å³æ¸…ç† GPU è¨˜æ†¶é«”
        try:
            import torch
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        except:
            pass
        
        # æˆåŠŸå¾Œé‡ç½®éŒ¯èª¤è¨ˆæ•¸
        _yolo_error_count = 0
        
    except RuntimeError as e:
        # è™•ç† NumPy ç›¸é—œçš„ RuntimeError
        if "Numpy is not available" in str(e) or "numpy" in str(e).lower():
            _yolo_error_count += 1
            current_time = time.time()
            # æ¯ 5 ç§’åªè¼¸å‡ºä¸€æ¬¡éŒ¯èª¤
            if current_time - _yolo_last_error_time > 5:
                print(f"[bus_vision] NumPy error (count: {_yolo_error_count}): {e}")
                print("[bus_vision] Attempting to reinitialize YOLO model...")
                _yolo_last_error_time = current_time
                # å˜—è©¦é‡æ–°åˆå§‹åŒ–æ¨¡å‹
                try:
                    yolo_model = None
                    _init_yolo_model()
                except Exception as reinit_err:
                    print(f"[bus_vision] Failed to reinitialize: {reinit_err}")
            return frame
        else:
            # å…¶ä»– RuntimeError
            _yolo_error_count += 1
            if _yolo_error_count % 10 == 0:  # æ¯ 10 æ¬¡éŒ¯èª¤è¼¸å‡ºä¸€æ¬¡
                print(f"[bus_vision] YOLO RuntimeError (count: {_yolo_error_count}): {e}")
            return frame
    except Exception as e:
        # å…¶ä»–éŒ¯èª¤
        _yolo_error_count += 1
        if _yolo_error_count % 10 == 0:  # æ¯ 10 æ¬¡éŒ¯èª¤è¼¸å‡ºä¸€æ¬¡
            print(f"[bus_vision] YOLO error (count: {_yolo_error_count}): {e}")
        return frame

    r0 = results[0]
    boxes = r0.boxes
    names = r0.names if hasattr(r0, "names") else {}
    
    # é¡¯ç¤ºæ‰€æœ‰å¯ç”¨çš„é¡åˆ¥åç¨±ï¼ˆç”¨æ–¼èª¿è©¦ï¼‰
    if isinstance(names, dict) and len(names) > 0:
        print(f"[bus_vision] ğŸ“‹ YOLO æ¨¡å‹æ”¯æ´çš„é¡åˆ¥: {list(names.values())[:10]}...")  # åªé¡¯ç¤ºå‰10å€‹

    num_boxes = 0 if boxes is None else len(boxes)
    # Debug: å°å‡ºé€™å¼µ frame YOLO æ‰¾åˆ°å¹¾å€‹æ¡†
    print(f"[bus_vision] ğŸ“Š YOLO åµæ¸¬çµæœï¼šæ‰¾åˆ° {num_boxes} å€‹ç‰©é«”ï¼ˆæ‰€æœ‰é¡åˆ¥ï¼Œconf>={YOLO_CONF}ï¼‰")
    print(f"[bus_vision] ğŸ” DEBUG: é–‹å§‹è™•ç† {num_boxes} å€‹æª¢æ¸¬æ¡†...")
    
    # å¦‚æœæ²’æœ‰åµæ¸¬åˆ°ä»»ä½•ç‰©é«”ï¼Œä¹Ÿè¦æ˜ç¢ºè¼¸å‡º
    if num_boxes == 0:
        print(f"[bus_vision] âš ï¸ æœ¬å¹€æœªåµæ¸¬åˆ°ä»»ä½•ç‰©é«”ï¼ˆconf>={YOLO_CONF}ï¼‰ï¼Œè·³é OCR")
        print(f"[bus_vision] ğŸ’¡ æç¤ºï¼šå¦‚æœæŒçºŒçœ‹ä¸åˆ°åµæ¸¬çµæœï¼Œå¯èƒ½æ˜¯å½±ç‰‡ä¸­æ²’æœ‰ç‰©é«”ï¼Œæˆ–éœ€è¦é€²ä¸€æ­¥é™ä½ YOLO_CONF")
        return frame  # æ²’æœ‰åµæ¸¬åˆ°ä»»ä½•ç‰©é«”ï¼Œç›´æ¥è¿”å›åŸ frameï¼ˆä¸åŸ·è¡Œ OCRï¼‰

    best_bus_text = None
    best_bus_no = None
    best_conf = 0.0

    if boxes is not None and len(boxes) > 0:
        print(f"[bus_vision] ğŸ” DEBUG: é€²å…¥ boxes å¾ªç’°ï¼Œæº–å‚™ç¹ªè£½æ¡†æ¡†...")
        box_count = 0
        bus_candidates = []  # ç”¨æ–¼æ”¶é›†æ‰€æœ‰å…¬è»Šå€™é¸æ¡†
        
        for box in boxes:
            box_count += 1
            print(f"[bus_vision] ğŸ” DEBUG: è™•ç†ç¬¬ {box_count}/{num_boxes} å€‹æ¡†...")
            cls_id = int(box.cls[0].item())
            conf = float(box.conf[0].item())
            cls_name = (
                names.get(cls_id, str(cls_id))
                if isinstance(names, dict)
                else str(cls_id)
            )

            print(f"[bus_vision] ğŸ“¦ åµæ¸¬åˆ°ç‰©é«”: cls_id={cls_id}, cls_name='{cls_name}', conf={conf:.3f}")

            # ---- æš«æ™‚é¡¯ç¤ºæ‰€æœ‰ YOLO åµæ¸¬åˆ°çš„ç‰©é«”ï¼ˆä¸åªæ˜¯å…¬è»Šé¡ï¼‰ï¼Œä»¥ä¾¿èª¿è©¦ ----
            # å…ˆç•«æ¡†æ¡†ï¼ˆæ‰€æœ‰ç‰©é«”éƒ½ç”¨è—è‰²æ¡†æ¡†æ¨™ç¤ºï¼‰
            x1, y1, x2, y2 = box.xyxy[0].tolist()
            x1, y1 = max(0, int(x1)), max(0, int(y1))
            x2, y2 = min(w - 1, int(x2)), min(h - 1, int(y2))
            
            # å…ˆç•«æ‰€æœ‰åµæ¸¬åˆ°çš„ç‰©é«”ï¼ˆè—è‰²æ¡†æ¡†ï¼‰ï¼Œé€™æ¨£å¯ä»¥çœ‹åˆ° YOLO æ˜¯å¦æœ‰åµæ¸¬åˆ°æ±è¥¿
            print(f"[bus_vision] ğŸ” DEBUG: æº–å‚™ç¹ªè£½è—è‰²æ¡†æ¡†ï¼Œåº§æ¨™: ({x1},{y1})-({x2},{y2})")
            try:
                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)  # è—è‰²æ¡†æ¡†ï¼šæ‰€æœ‰åµæ¸¬åˆ°çš„ç‰©é«”
                cv2.putText(
                    frame,
                    f"{cls_name} {conf:.2f}",
                    (int(x1), max(0, int(y1) - 5)),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.5,
                    (255, 0, 0),
                    1,
                    cv2.LINE_AA,
                )
                print(f"[bus_vision] ğŸ”µ å·²ç•«è—è‰²æ¡†æ¡†ï¼ˆæ‰€æœ‰ç‰©é«”ï¼‰: {cls_name} (conf={conf:.2f}), åº§æ¨™: ({x1},{y1})-({x2},{y2})")
            except Exception as draw_err:
                print(f"[bus_vision] âŒ ç¹ªè£½è—è‰²æ¡†æ¡†æ™‚ç™¼ç”ŸéŒ¯èª¤: {draw_err}")
                import traceback
                traceback.print_exc()

            # ---- é€™è£¡æ˜¯é—œéµï¼šå…ˆè¦æœ‰ YOLO åµæ¸¬åˆ°å…¬è»Šå¾Œæ‰èƒ½é–‹å•Ÿ OCR ----
            # è¦–è¦ºä¸Šä»»ä½•ã€Œè»Šã€éƒ½å…ˆç•¶æˆå€™é¸ï¼šbus / truck / car / è‡ªè¨‚ bus class
            cls_l = cls_name.lower()
            is_bus_like = (
                "bus" in cls_l
                or "truck" in cls_l
                or "car" in cls_l
                or "vehicle" in cls_l
                or "motorcycle" in cls_l  # æŸäº›æƒ…æ³ä¸‹å¯èƒ½èª¤åˆ¤ï¼Œä½†å…ˆåŒ…å«
            )
            # å¦‚æœä½ ç”¨çš„æ˜¯è‡ªè¨‚ bus æ¨¡å‹ï¼Œclass 0 åå­—å¯èƒ½å°±æ˜¯ "bus"
            # ä¸Šé¢é€™æ¢å°±æœƒæˆç«‹

            if not is_bus_like:
                print(f"[bus_vision] â­ï¸ è·³ééå…¬è»Šé¡ç‰©é«”: {cls_name} (ç¹¼çºŒæª¢æŸ¥ä¸‹ä¸€å€‹)")
                continue

            # åªæœ‰ç•¶ YOLO åµæ¸¬åˆ°å…¬è»Šé¡ç‰©é«”æ™‚ï¼Œæ‰ç•«ç¶ è‰²æ¡†æ¡†ä¸¦åŸ·è¡Œ OCR
            # åœ¨è—è‰²æ¡†æ¡†ä¸Šå†ç•«ä¸€å€‹ç¶ è‰²æ¡†æ¡†ï¼ˆæ›´ç²—ï¼‰ï¼Œè¡¨ç¤ºé€™æ˜¯å…¬è»Šé¡ç‰©é«”
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)  # ç¶ è‰²æ¡†æ¡†ï¼šå…¬è»Šé¡ç‰©é«”
            print(f"[bus_vision] âœ… YOLO åµæ¸¬åˆ°å…¬è»Šé¡ç‰©é«”: {cls_name} (conf={conf:.2f}), åº§æ¨™: ({x1},{y1})-({x2},{y2})")
            
            # æ”¶é›†å€™é¸çš„å…¬è»Šæ¡†ï¼Œç¨å¾Œåªå°ä¿¡å¿ƒåº¦æœ€é«˜çš„ä¸€å€‹é€²è¡Œ OCR
            bus_candidates.append({
                "box": box,
                "cls_name": cls_name,
                "conf": conf,
                "coords": (x1, y1, x2, y2)
            })

    # ---- é‡å°ä¿¡å¿ƒåº¦æœ€é«˜çš„å…¬è»Šæ¡†é€²è¡Œ OCR ----
    if bus_candidates:
        # æ‰¾å‡º YOLO ä¿¡å¿ƒåº¦æœ€é«˜çš„æ¡†
        best_candidate = max(bus_candidates, key=lambda x: x["conf"])
        x1, y1, x2, y2 = best_candidate["coords"]
        cls_name = best_candidate["cls_name"]
        conf = best_candidate["conf"]
        
        print(f"[bus_vision] ğŸ¯ é¸æ“‡ä¿¡å¿ƒåº¦æœ€é«˜çš„å…¬è»Šæ¡†é€²è¡Œ OCR: {cls_name} (conf={conf:.2f})")
        print(f"[bus_vision] ğŸŸ¢ å·²ç•«ç¶ è‰²æ¡†æ¡†ï¼ˆå…¬è»Šé¡ï¼‰ï¼Œç¾åœ¨é–‹å§‹ OCR è¾¨è­˜...")

        # 2) å– bus ä¸ŠåŠéƒ¨ç•¶ LED é¡¯ç¤ºå€ï¼ˆåªæœ‰ YOLO åµæ¸¬åˆ°å…¬è»Šå¾Œæ‰åŸ·è¡Œ OCRï¼‰
        box_h = y2 - y1
        roi_top = y1
        roi_bottom = y1 + max(10, box_h // 2)
        roi_left = x1
        roi_right = x2

        roi = frame[roi_top:roi_bottom, roi_left:roi_right]
        if roi.size == 0:
            print(f"[bus_vision] âš  ROI ç‚ºç©ºï¼Œè·³é OCR")
        else:
            roi_for_ocr = _preprocess_roi_for_ocr(roi)

            # 3) EasyOCRï¼ˆåªæœ‰ YOLO åµæ¸¬åˆ°å…¬è»Šå¾Œæ‰åŸ·è¡Œ OCRï¼‰
            print(f"[bus_vision] ğŸ” é–‹å§‹ OCR è¾¨è­˜ï¼ˆYOLO å·²åµæ¸¬åˆ°å…¬è»Šï¼‰...")
            
            # OCR è™•ç†å‰æ¸…ç† GPU è¨˜æ†¶é«”
            try:
                import torch
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
            except:
                pass
            
            try:
                ocr_result = ocr_reader.readtext(
                    roi_for_ocr,
                    detail=1,
                    paragraph=False,
                )
                # OCR è™•ç†å¾Œç«‹å³æ¸…ç† GPU è¨˜æ†¶é«”
                try:
                    import torch
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                except:
                    pass
            except RuntimeError as e:
                if "CUDA" in str(e) or "out of memory" in str(e).lower():
                    print(f"[bus_vision] âŒ OCR GPU è¨˜æ†¶é«”ä¸è¶³ï¼Œæ¸…ç†è¨˜æ†¶é«”å¾Œè·³éæ­¤ ROI")
                    # å¼·åˆ¶æ¸…ç† GPU è¨˜æ†¶é«”
                    try:
                        import torch
                        if torch.cuda.is_available():
                            torch.cuda.empty_cache()
                            import gc
                            gc.collect()
                            torch.cuda.empty_cache()  # å†æ¬¡æ¸…ç†
                    except:
                        pass
                    ocr_result = [] # ç¢ºä¿å¾ŒçºŒé‚è¼¯èƒ½ç¹¼çºŒ
                else:
                    print(f"[bus_vision] âŒ OCR error: {e}")
                    ocr_result = []
            except Exception as e:
                print(f"[bus_vision] âŒ OCR error: {e}")
                # æ¸…ç† GPU è¨˜æ†¶é«”
                try:
                    import torch
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                except:
                    pass
                ocr_result = []

            text_pieces = []
            best_score_local = 0.0

            if isinstance(ocr_result, list):
                for item in ocr_result:
                    if not isinstance(item, (list, tuple)) or len(item) != 3:
                        continue
                    bbox, txt, score = item
                    txt = str(txt).strip()
                    if not txt:
                        continue
                    text_pieces.append(txt)
                    try:
                        score_f = float(score)
                    except Exception:
                        score_f = 0.0
                    if score_f > best_score_local:
                        best_score_local = score_f

            full_text = "".join(text_pieces)
            if full_text:
                candidate_no = _extract_bus_number_from_text(full_text)
                # åªæœ‰ç•¶æå–åˆ°æ•¸å­—æ™‚æ‰è¨˜éŒ„ï¼ˆä¸è¦è‹±æ–‡ï¼‰
                if candidate_no:
                    # ä½¿ç”¨ OCR çš„ confidence ä½œç‚ºè¾¨è­˜åº¦
                    ocr_confidence = best_score_local if best_score_local > 0 else 0.5
                    _update_bus_status(candidate_no, full_text, ocr_confidence)
                    _save_roi_debug_image(roi, candidate_no)
            else:
                candidate_no = None

            label_txt = candidate_no or "---"
            label = f"{cls_name.upper()}? {label_txt} ({best_score_local:.2f})"
            cv2.putText(
                frame,
                label,
                (x1, max(0, roi_top - 10)),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (0, 255, 0),
                2,
                cv2.LINE_AA,
            )

            if candidate_no and best_score_local > best_conf:
                best_conf = best_score_local
                best_bus_no = candidate_no
                best_bus_text = full_text

    # æ³¨æ„ï¼š_update_bus_status ç¾åœ¨åœ¨æå–åˆ°æ•¸å­—æ™‚å°±æœƒè¢«èª¿ç”¨
    # é€™è£¡åªè¨˜éŒ„æœ€å¾Œä¸€æ¬¡çš„æœ€ä½³çµæœï¼ˆç”¨æ–¼æ—¥èªŒï¼‰
    if best_bus_no is not None:
        print(
            f"[bus_vision] BUS NUMBER DETECTED: {best_bus_no} "
            f"(conf={best_conf:.2f}, raw='{best_bus_text}')"
        )
    
    print(f"[bus_vision] ğŸ” DEBUG: _process_frame å®Œæˆï¼Œè¿”å›è™•ç†å¾Œçš„ frameï¼ˆæ‡‰åŒ…å«æ¡†æ¡†ï¼‰")
    print(f"[bus_vision] ğŸ” DEBUG: Frame shape: {frame.shape if frame is not None else 'None'}, dtype: {frame.dtype if frame is not None else 'None'}")

    return frame


# ---------------- Streaming generator ----------------

def bus_video_generator():
    """
    StreamingResponse ç”¨çš„ generatorã€‚
    æ§åˆ¶ï¼š
      - _bus_running ç‚º False æ™‚è·³å‡º
      - æ¯ _DETECT_INTERVAL å¼µ frame è·‘ä¸€æ¬¡ YOLO+OCR
    """
    global _bus_running, _last_annotated_frame, _use_mobile_camera

    # å¦‚æœé‚„æ²’æœ‰å•Ÿå‹•ï¼Œå…ˆç™¼é€ç­‰å¾…ç•«é¢ï¼Œç„¶å¾Œç­‰å¾…å•Ÿå‹•
    if not _bus_running:
        print("[bus_vision] Bus vision not started yet, sending waiting frame...")
        # ç™¼é€ä¸€å€‹ç­‰å¾…ç•«é¢ï¼ˆç°è‰²èƒŒæ™¯ï¼Œç™½è‰²æ–‡å­—ï¼‰
        waiting_frame = np.zeros((480, 640, 3), dtype=np.uint8)
        waiting_frame.fill(64)  # æ·±ç°è‰²èƒŒæ™¯
        # æ·»åŠ æ–‡å­—æç¤ºï¼ˆä½¿ç”¨ OpenCV çš„æ–‡å­—ç¹ªè£½ï¼‰
        # cv2 å·²ç¶“åœ¨æ–‡ä»¶é ‚éƒ¨å°å…¥ï¼Œä¸éœ€è¦é‡æ–°å°å…¥
        cv2.putText(waiting_frame, "Waiting for camera...", (50, 240), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        ret, jpeg = cv2.imencode(".jpg", waiting_frame)
        if ret:
            frame_bytes = jpeg.tobytes()
            yield (
                b"--frame\r\n"
                b"Content-Type: image/jpeg\r\n\r\n" + frame_bytes + b"\r\n"
            )
        # ç­‰å¾…æœ€å¤š10ç§’ï¼Œæ¯ç§’æª¢æŸ¥ä¸€æ¬¡ï¼ˆå¢åŠ ç­‰å¾…æ™‚é–“ï¼Œå› ç‚ºå‰ç«¯å¯èƒ½éœ€è¦æ™‚é–“å•Ÿå‹•ï¼‰
        wait_count = 0
        while not _bus_running and wait_count < 100:  # 100 * 0.1 = 10ç§’
            time.sleep(0.1)
            wait_count += 1
        if not _bus_running:
            print("[bus_vision] Timeout waiting for bus vision to start. Will keep showing waiting frame.")
            # ä¸ç›´æ¥è¿”å›ï¼Œè€Œæ˜¯æŒçºŒç™¼é€ç­‰å¾…ç•«é¢ï¼Œç›´åˆ°å•Ÿå‹•ç‚ºæ­¢
            while not _bus_running:
                waiting_frame = np.zeros((480, 640, 3), dtype=np.uint8)
                waiting_frame.fill(64)
                cv2.putText(waiting_frame, "Waiting for camera...", (50, 240), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
                ret, jpeg = cv2.imencode(".jpg", waiting_frame)
                if ret:
                    frame_bytes = jpeg.tobytes()
                    yield (
                        b"--frame\r\n"
                        b"Content-Type: image/jpeg\r\n\r\n" + frame_bytes + b"\r\n"
                    )
                time.sleep(0.5)  # æ¯ 0.5 ç§’æª¢æŸ¥ä¸€æ¬¡
            # ä¸€æ—¦å•Ÿå‹•ï¼Œç¹¼çºŒåŸ·è¡Œä¸‹é¢çš„é‚è¼¯

    if not _use_mobile_camera:
        _open_camera()
        if _cap is None:
            if _use_video_file:
                print("[bus_vision] Video file not available.")
            else:
                print("[bus_vision] Camera not available.")
            return
        if _use_video_file:
            print("[bus_vision] Using video file stream.")
        else:
            print("[bus_vision] Using local camera stream.")
    else:
        print("[bus_vision] Using mobile camera stream.")

    frame_idx = 0
    print("[bus_vision] Start video streaming loop.")

    consecutive_errors = 0
    max_consecutive_errors = 10
    last_frame_time = time.time()
    
    # ç¢ºå®šä½¿ç”¨çš„ frame intervalï¼ˆå½±ç‰‡æ¨¡å¼ä½¿ç”¨è¼ƒæ…¢çš„é€Ÿåº¦ï¼Œè®“ YOLO æœ‰è¶³å¤ æ™‚é–“è™•ç†ï¼‰
    if _use_video_file:
        # å½±ç‰‡æ¨¡å¼ï¼šä½¿ç”¨æ­£å¸¸çš„æ’­æ”¾é€Ÿåº¦ï¼Œç¢ºä¿å½±ç‰‡çœ‹èµ·ä¾†æµæš¢
        # é›–ç„¶æˆ‘å€‘è¨­ç‚º _TARGET_FPS (30)ï¼Œä½† bus_video_generator æœƒç›¡é‡ä½¿ç”¨å½±ç‰‡åŸå§‹ FPS
        if _video_frame_interval is not None:
            frame_interval = _video_frame_interval
        else:
            frame_interval = _FRAME_INTERVAL
    else:
        frame_interval = _FRAME_INTERVAL  # ä½¿ç”¨é è¨­ FPS
        print(f"[bus_vision] ä½¿ç”¨é è¨­ FPS æ§åˆ¶æ’­æ”¾é€Ÿåº¦ï¼ˆ{1.0/frame_interval:.2f} FPSï¼‰")
    
    # ç¢ºä¿åªæœ‰åœ¨ _bus_running ç‚º True æ™‚æ‰è™•ç†
    while _bus_running:
        try:
            # FPS æ§åˆ¶ï¼šç¢ºä¿ä¸æœƒéåº¦è™•ç†ï¼ˆå›ºå®šç‚ºæ­£å¸¸é€Ÿåº¦ï¼Œä¸å—æ¨¡æ“¬é€Ÿåº¦å½±éŸ¿ï¼‰
            current_time = time.time()
            elapsed = current_time - last_frame_time
            if elapsed < frame_interval:
                time.sleep(frame_interval - elapsed)
            last_frame_time = time.time()
            
            ret, frame = _get_frame()
            if not ret or frame is None:
                consecutive_errors += 1
                if consecutive_errors > max_consecutive_errors:
                    # é€£çºŒéŒ¯èª¤å¤ªå¤šï¼Œç™¼é€ä¸€å€‹ç°è‰²ç­‰å¾…ç•«é¢ï¼ˆä¸æ˜¯é»‘è‰²ï¼Œé¿å…çœ‹èµ·ä¾†åƒé»‘å±ï¼‰
                    waiting_frame = np.zeros((480, 640, 3), dtype=np.uint8)
                    waiting_frame.fill(64)  # æ·±ç°è‰²
                    cv2.putText(waiting_frame, "Waiting for frame...", (50, 240), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
                    ret, jpeg = cv2.imencode(".jpg", waiting_frame, [cv2.IMWRITE_JPEG_QUALITY, 70])
                    if ret:
                        frame_bytes = jpeg.tobytes()
                        yield (
                            b"--frame\r\n"
                            b"Content-Type: image/jpeg\r\n\r\n" + frame_bytes + b"\r\n"
                        )
                # ä½¿ç”¨æ­£ç¢ºçš„ frame intervalï¼ˆå½±ç‰‡æ¨¡å¼ä½¿ç”¨å½±ç‰‡ FPSï¼Œå…¶ä»–ä½¿ç”¨é è¨­ï¼‰
                # åŠ å¿«æ’­æ”¾é€Ÿåº¦ï¼šå¦‚æœä½¿ç”¨äº† _video_frame_intervalï¼Œå°‡å…¶é™¤ä»¥ 2.0 (2å€é€Ÿ)
                sleep_interval = (_video_frame_interval / 2.0) if (_use_video_file and _video_frame_interval is not None) else _FRAME_INTERVAL
                time.sleep(sleep_interval)
                continue

            consecutive_errors = 0  # é‡ç½®éŒ¯èª¤è¨ˆæ•¸
            frame_idx += 1
            
            # æ¯è™•ç†ä¸€å®šæ•¸é‡çš„ frame å¾Œï¼Œå¼·åˆ¶åƒåœ¾å›æ”¶å’Œ GPU è¨˜æ†¶é«”æ¸…ç†
            if frame_idx % 10 == 0:  # æ¯ 10 å¹€æ¸…ç†ä¸€æ¬¡ï¼ˆæ›´é »ç¹åœ°æ¸…ç†ä»¥æ¸›å°‘è¨˜æ†¶é«”ç´¯ç©ï¼‰
                import gc
                gc.collect()
                # æ¸…ç† GPU è¨˜æ†¶é«”
                try:
                    import torch
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                        # å¼·åˆ¶åŒæ­¥ä»¥ç¢ºä¿æ¸…ç†å®Œæˆ
                        torch.cuda.synchronize()
                except:
                    pass

            # åªåœ¨éœ€è¦æ™‚è™•ç†ï¼ˆé™ä½è™•ç†é »ç‡ï¼‰ï¼Œä½†é¡¯ç¤ºè¦å³æ™‚
            # è™•ç†å’Œé¡¯ç¤ºåˆ†é›¢ï¼šè™•ç†å¯ä»¥æ…¢ï¼Œä½†é¡¯ç¤ºè¦æµæš¢
            # é—œéµï¼šé¡¯ç¤ºè™•ç†å¾Œçš„ frameï¼ˆåŒ…å« YOLO æ¡†æ¡†å’Œ OCR çµæœï¼‰
            # å…ˆè¦æœ‰ YOLO åµæ¸¬åˆ°å…¬è»Šå¾Œæ‰èƒ½é–‹å•Ÿ OCRï¼ˆåœ¨ _process_frame ä¸­å¯¦ç¾ï¼‰
            if _use_video_file:
                # å½±ç‰‡æ¨¡å¼ï¼šæ¯å¹€éƒ½é€²è¡Œ YOLO åµæ¸¬ï¼ˆç¢ºä¿ YOLO æ¨¡å‹è¢«ä½¿ç”¨ï¼‰
                # é¡¯ç¤ºè™•ç†å¾Œçš„ frameï¼ˆåŒ…å« YOLO æ¡†æ¡†å’Œ OCR çµæœï¼‰
                if frame_idx % _DETECT_INTERVAL == 0 or _last_annotated_frame is None:
                    print(f"[bus_vision] ğŸ“¹ å½±ç‰‡æ¨¡å¼ï¼šè™•ç†ç¬¬ {frame_idx} å¹€ï¼Œèª¿ç”¨ YOLO æ¨¡å‹...")
                    try:
                        process_start = time.time()
                        annotated = _process_frame(frame)
                        process_time = time.time() - process_start
                        if process_time > 0.3:
                            print(f"[bus_vision] Warning: Frame processing took {process_time:.2f}s (slow)")
                        
                        # ç¢ºä¿è™•ç†å¾Œçš„ frame æœ‰æ•ˆ
                        if annotated is not None and isinstance(annotated, np.ndarray) and annotated.size > 0:
                            _last_annotated_frame = annotated.copy()  # æ›´æ–°ç·©å­˜
                            # ä½¿ç”¨è™•ç†å¾Œçš„ frameï¼ˆåŒ…å« YOLO æ¡†æ¡†ï¼‰
                        else:
                            # å¦‚æœè™•ç†å¤±æ•—ï¼Œä½¿ç”¨åŸ frame
                            annotated = frame
                    except Exception as proc_err:
                        # è™•ç† frame æ™‚å‡ºéŒ¯ï¼Œä½¿ç”¨åŸ frame
                        print(f"[bus_vision] è™•ç† frame éŒ¯èª¤: {proc_err}")
                        annotated = frame
                else:
                    # æ²’æœ‰æ–°çš„è™•ç†çµæœæ™‚ï¼Œé¡¯ç¤ºæœ€æ–°çš„è™•ç†çµæœï¼ˆåŒ…å« YOLO æ¡†æ¡†ï¼‰
                    if _last_annotated_frame is not None and isinstance(_last_annotated_frame, np.ndarray):
                        annotated = _last_annotated_frame.copy()
                    else:
                        annotated = frame
            else:
                # å³æ™‚å½±åƒæ¨¡å¼ï¼šä½¿ç”¨åŸæœ‰é‚è¼¯
                if frame_idx % _DETECT_INTERVAL == 0 or _last_annotated_frame is None:
                    try:
                        # æ·»åŠ è¶…æ™‚ä¿è­·ï¼ˆæœ€å¤šç­‰å¾… 0.3 ç§’ï¼Œé¿å…å¡é “ï¼‰
                        process_start = time.time()
                        annotated = _process_frame(frame)
                        process_time = time.time() - process_start
                        if process_time > 0.3:
                            print(f"[bus_vision] Warning: Frame processing took {process_time:.2f}s (slow)")
                        
                        # ç¢ºä¿è™•ç†å¾Œçš„ frame æœ‰æ•ˆ
                        if annotated is not None and isinstance(annotated, np.ndarray) and annotated.size > 0:
                            _last_annotated_frame = annotated.copy()  # è¤‡è£½ä»¥é¿å…è¨˜æ†¶é«”å•é¡Œ
                            annotated = annotated  # ä½¿ç”¨è™•ç†å¾Œçš„ frame
                        else:
                            # å¦‚æœè™•ç†å¤±æ•—ï¼Œä½¿ç”¨åŸ frameï¼ˆç¢ºä¿ç•«é¢å³æ™‚ï¼‰
                            annotated = frame
                    except Exception as proc_err:
                        # è™•ç† frame æ™‚å‡ºéŒ¯ï¼Œä½¿ç”¨åŸ frameï¼ˆç¢ºä¿ç•«é¢å³æ™‚ï¼‰
                        print(f"[bus_vision] è™•ç† frame éŒ¯èª¤: {proc_err}")
                        annotated = frame
                else:
                    # æ²’æœ‰æ–°çš„è™•ç†çµæœæ™‚ï¼Œé¡¯ç¤ºæœ€æ–°çš„åŸå§‹ frameï¼ˆç¢ºä¿å³æ™‚æ€§ï¼‰
                    annotated = frame

            # ç¢ºä¿ annotated æœ‰æ•ˆä¸”ä¸ç‚ºç©º
            if annotated is None or not isinstance(annotated, np.ndarray) or annotated.size == 0:
                print(f"[bus_vision] âš ï¸ DEBUG: annotated frame ç„¡æ•ˆï¼Œä½¿ç”¨åŸ frame")
                annotated = frame
            else:
                print(f"[bus_vision] ğŸ” DEBUG: annotated frame æœ‰æ•ˆï¼Œshape: {annotated.shape}, dtype: {annotated.dtype}")

            # é™ä½ JPEG å“è³ªä»¥åŠ å¿«å‚³è¼¸ï¼ˆ70% å“è³ªï¼Œå¹³è¡¡å“è³ªå’Œé€Ÿåº¦ï¼Œç¢ºä¿å³æ™‚æ€§ï¼‰
            print(f"[bus_vision] ğŸ” DEBUG: æº–å‚™ç·¨ç¢¼ frame ç‚º JPEG...")
            ret, jpeg = cv2.imencode(".jpg", annotated, [cv2.IMWRITE_JPEG_QUALITY, 70])
            if ret:
                print(f"[bus_vision] ğŸ” DEBUG: JPEG ç·¨ç¢¼æˆåŠŸï¼Œå¤§å°: {len(jpeg.tobytes())} bytes")
            else:
                print(f"[bus_vision] âŒ DEBUG: JPEG ç·¨ç¢¼å¤±æ•—ï¼")
            if not ret:
                # å¦‚æœç·¨ç¢¼å¤±æ•—ï¼Œç™¼é€åŸ frame
                ret, jpeg = cv2.imencode(".jpg", frame, [cv2.IMWRITE_JPEG_QUALITY, 70])
                if not ret:
                    continue
            
            frame_bytes = jpeg.tobytes()

            yield (
                b"--frame\r\n"
                b"Content-Type: image/jpeg\r\n\r\n" + frame_bytes + b"\r\n"
            )
        except Exception as e:
            # æ•ç²æ‰€æœ‰ç•°å¸¸ï¼Œé¿å…è¦–è¨Šæµä¸­æ–·
            print(f"[bus_vision] è¦–è¨ŠæµéŒ¯èª¤: {e}")
            consecutive_errors += 1
            if consecutive_errors > max_consecutive_errors:
                # ç™¼é€ç°è‰²ç­‰å¾…ç•«é¢ï¼ˆä¸æ˜¯é»‘è‰²ï¼‰
                try:
                    waiting_frame = np.zeros((480, 640, 3), dtype=np.uint8)
                    waiting_frame.fill(64)  # æ·±ç°è‰²
                    cv2.putText(waiting_frame, "Stream error, retrying...", (30, 240), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                    ret, jpeg = cv2.imencode(".jpg", waiting_frame, [cv2.IMWRITE_JPEG_QUALITY, 70])
                    if ret:
                        frame_bytes = jpeg.tobytes()
                        yield (
                            b"--frame\r\n"
                            b"Content-Type: image/jpeg\r\n\r\n" + frame_bytes + b"\r\n"
                        )
                except:
                    pass
            # ä½¿ç”¨æ­£ç¢ºçš„ frame intervalï¼ˆå½±ç‰‡æ¨¡å¼ä½¿ç”¨å½±ç‰‡ FPSï¼Œå…¶ä»–ä½¿ç”¨é è¨­ï¼‰
            # åŠ å¿«æ’­æ”¾é€Ÿåº¦ï¼šå¦‚æœä½¿ç”¨äº† _video_frame_intervalï¼Œå°‡å…¶é™¤ä»¥ 2.0 (2å€é€Ÿ)
            sleep_interval = (_video_frame_interval / 2.0) if (_use_video_file and _video_frame_interval is not None) else _FRAME_INTERVAL
            time.sleep(sleep_interval)

    print("[bus_vision] Stop video streaming loop.")
    if not _use_mobile_camera:
        _close_camera()
    else:
        # æ¸…ç©ºæ‰‹æ©Ÿè¦–è¨Šæµ queue
        with _mobile_frame_lock:
            _mobile_frame_queue = None


# ---------------- å¤–éƒ¨ API ----------------

def start_bus_vision(use_mobile: bool = False, video_file_path: Optional[str] = None, start_sec: float = 0.0, end_sec: Optional[float] = None):
    """
    å•Ÿå‹•å…¬è»Šè¾¨è­˜ç³»çµ±
    
    Args:
        use_mobile: æ˜¯å¦ä½¿ç”¨æ‰‹æ©Ÿæ”å½±æ©Ÿï¼ˆé è¨­ Falseï¼‰
        video_file_path: å½±ç‰‡æª”æ¡ˆè·¯å¾‘ï¼ˆå¦‚æœæä¾›ï¼Œæœƒå„ªå…ˆä½¿ç”¨å½±ç‰‡æª”æ¡ˆï¼‰
        start_sec: å½±ç‰‡é–‹å§‹æ™‚é–“ï¼ˆç§’ï¼‰ï¼Œåƒ…åœ¨å½±ç‰‡æ¨¡å¼ä¸‹æœ‰æ•ˆ
        end_sec: å½±ç‰‡çµæŸæ™‚é–“ï¼ˆç§’ï¼‰ï¼Œåƒ…åœ¨å½±ç‰‡æ¨¡å¼ä¸‹æœ‰æ•ˆ
    
    æ³¨æ„ï¼šé…ç½®æª”æ¡ˆä¸­çš„è¨­å®šï¼ˆINPUT_MODE å’Œ VIDEO_FILE_PATHï¼‰å„ªå…ˆæ–¼ API åƒæ•¸
    """
    global _bus_running, _use_mobile_camera, _use_video_file, _video_file_path, _mobile_frame_queue
    global _video_start_sec, _video_end_sec
    
    # è‹¥å·²é‹è¡Œï¼Œå…ˆåœæ­¢ä»¥å¥—ç”¨æ–°çš„æ’­æ”¾å€é–“
    if _bus_running:
        try:
            stop_bus_vision()
        except Exception:
            pass
    _bus_running = False

    # è‹¥ä½¿ç”¨å½±ç‰‡ä¾†æºï¼Œå¼·åˆ¶æ’­æ”¾ 6~8 ç§’å€é–“
    enforce_video_window = False
    if video_file_path:
        enforce_video_window = True
    if INPUT_MODE == "video" and VIDEO_FILE_PATH:
        enforce_video_window = True
        video_file_path = VIDEO_FILE_PATH
        use_mobile = False
        print(f"[bus_vision] é…ç½®æª”æ¡ˆè¨­å®šç‚ºå½±ç‰‡æ¨¡å¼ï¼Œä½¿ç”¨å½±ç‰‡æª”æ¡ˆï¼š{video_file_path}")

    default_start = 0.0
    default_end = None
    if enforce_video_window:
        start_sec = 6.0
        end_sec = 8.0
        default_start = 6.0
        default_end = 8.0

    _bus_running = True
    
    # è¨­å®šèµ·å§‹æ™‚é–“èˆ‡çµæŸæ™‚é–“
    _video_start_sec = start_sec if start_sec is not None else default_start
    _video_end_sec = end_sec if end_sec is not None else default_end
    print(f"[bus_vision] å½±ç‰‡æ’­æ”¾å€é–“è¨­å®š: {start_sec}s ~ {end_sec if end_sec else 'End'}s")
    
    # å„ªå…ˆä½¿ç”¨é…ç½®æª”æ¡ˆä¸­çš„è¨­å®šï¼ˆå¦‚æœé…ç½®ç‚ºå½±ç‰‡æ¨¡å¼ï¼Œå¼·åˆ¶ä½¿ç”¨å½±ç‰‡ï¼Œå¿½ç•¥ use_mobile åƒæ•¸ï¼‰
    if INPUT_MODE == "video" and VIDEO_FILE_PATH:
        # é…ç½®æª”æ¡ˆè¨­å®šç‚ºå½±ç‰‡æ¨¡å¼ï¼Œå¼·åˆ¶ä½¿ç”¨å½±ç‰‡æª”æ¡ˆ
        video_file_path = VIDEO_FILE_PATH
        use_mobile = False  # å¼·åˆ¶ä¸ä½¿ç”¨æ‰‹æ©Ÿæ¨¡å¼
        print(f"[bus_vision] é…ç½®æª”æ¡ˆè¨­å®šç‚ºå½±ç‰‡æ¨¡å¼ï¼Œä½¿ç”¨å½±ç‰‡æª”æ¡ˆï¼š{video_file_path}")
    elif INPUT_MODE == "realtime":
        # é…ç½®æª”æ¡ˆè¨­å®šç‚ºå³æ™‚å½±åƒæ¨¡å¼
        if video_file_path is None:
            # å¦‚æœæ²’æœ‰æä¾›å½±ç‰‡è·¯å¾‘ï¼Œä½¿ç”¨æ‰‹æ©Ÿæ¨¡å¼
            use_mobile = True
            video_file_path = None
    # å¦‚æœ INPUT_MODE ä¸æ˜¯ "video" ä¹Ÿä¸æ˜¯ "realtime"ï¼Œå‰‡ä½¿ç”¨ API åƒæ•¸
    
    # è¨­å®šè¼¸å…¥ä¾†æº
    if video_file_path:
        # ä½¿ç”¨å½±ç‰‡æª”æ¡ˆæ¨¡å¼
        _use_mobile_camera = False
        _use_video_file = True
        _video_file_path = video_file_path
        print(f"[bus_vision] Bus vision started (video file mode): {video_file_path}")
        print(f"[bus_vision] æ³¨æ„ï¼šå½±ç‰‡æ¨¡å¼ä¸‹ä¸æœƒä½¿ç”¨æ‰‹æ©Ÿæ”åƒé ­")
    elif use_mobile:
        # ä½¿ç”¨æ‰‹æ©Ÿæ”å½±æ©Ÿæ¨¡å¼
        _use_mobile_camera = True
        _use_video_file = False
        _video_file_path = None
        with _mobile_frame_lock:
            _mobile_frame_queue = []
        print("[bus_vision] Bus vision started (mobile camera mode).")
    else:
        # ä½¿ç”¨é›»è…¦æ”å½±æ©Ÿæ¨¡å¼
        _use_mobile_camera = False
        _use_video_file = False
        _video_file_path = None
        print("[bus_vision] Bus vision started (local camera mode).")
    return True


def stop_bus_vision():
    """åœæ­¢å…¬è»Šè¾¨è­˜ï¼Œå®Œå…¨é—œé–‰AIæ¨¡å‹"""
    global _bus_running, _use_mobile_camera, _use_video_file, _video_file_path, _mobile_frame_queue
    global _video_fps, _video_frame_interval, _last_video_frame, yolo_model
    
    _bus_running = False
    _use_mobile_camera = False
    _use_video_file = False
    _video_file_path = None
    _video_fps = None
    _video_frame_interval = None
    _last_video_frame = None
    
    # æ¸…ç©ºæ‰‹æ©Ÿè¦–è¨Šæµå¿«å–
    with _mobile_frame_lock:
        _mobile_frame_queue = None
    
    # é—œé–‰æ”å½±æ©Ÿæˆ–å½±ç‰‡æª”æ¡ˆ
    _close_camera()
    
    # æ³¨æ„ï¼šä¸é‡‹æ”¾ YOLO æ¨¡å‹ï¼Œå› ç‚ºé‡æ–°è¼‰å…¥å¾ˆæ…¢
    # ä½†ç¢ºä¿ä¸æœƒå†è™•ç†æ–°çš„ frame
    print("[bus_vision] Bus vision stopped. AI model is no longer processing frames.")


def reset_bus_vision():
    """é‡ç½®æ‰€æœ‰å…¬è»Šè¾¨è­˜ç‹€æ…‹å’Œå¿«å–ï¼Œæ¸…é™¤æ‰€æœ‰ç”¨ä¸åˆ°çš„æ±è¥¿"""
    global _bus_running, _use_mobile_camera, _use_video_file, _video_file_path, _mobile_frame_queue
    global _video_fps, _video_frame_interval, _last_video_frame
    global last_bus_status, _recent_detections, _last_annotated_frame
    global _yolo_error_count, _yolo_last_error_time
    
    # åœæ­¢é‹è¡Œ
    _bus_running = False
    _use_mobile_camera = False
    _use_video_file = False
    _video_file_path = None
    _video_fps = None
    _video_frame_interval = None
    _last_video_frame = None
    
    # æ¸…ç©ºæ‰‹æ©Ÿè¦–è¨Šæµå¿«å–
    with _mobile_frame_lock:
        if _mobile_frame_queue is not None:
            _mobile_frame_queue.clear()
            _mobile_frame_queue = None
    
    # é‡ç½®ç‹€æ…‹
    with _status_lock:
        last_bus_status = {
            "bus_number": None,
            "raw_text": None,
            "confidence": 0.0,
            "last_seen_ts": None,
        }
    
    # æ¸…ç©ºåµæ¸¬è¨˜éŒ„
    with _detection_lock:
        _recent_detections.clear()
        _recent_detections = []
    
    # æ¸…é™¤å¿«å–çš„ frame
    _last_annotated_frame = None
    
    # é‡ç½®éŒ¯èª¤è¨ˆæ•¸
    _yolo_error_count = 0
    _yolo_last_error_time = 0
    
    # é—œé–‰æ”å½±æ©Ÿ
    _close_camera()
    
    # å¼·åˆ¶åƒåœ¾å›æ”¶
    import gc
    gc.collect()
    
    print("[bus_vision] Bus vision reset complete. All caches cleared.")


def get_bus_status() -> Dict:
    """å›å‚³æœ€è¿‘ä¸€æ¬¡è¾¨è­˜çµæœå’Œæ‰€æœ‰åµæ¸¬åˆ°çš„è™Ÿç¢¼ï¼ˆthread-safeï¼‰"""
    with _status_lock:
        result = dict(last_bus_status)
    
    # è¨ˆç®—æœ€è¿‘5æ¬¡åµæ¸¬çš„ä¿¡å¿ƒåº¦
    with _detection_lock:
        recent = list(_recent_detections)
    
    # çµ±è¨ˆæ¯å€‹è™Ÿç¢¼çš„å‡ºç¾æ¬¡æ•¸å’Œå¹³å‡ä¿¡å¿ƒåº¦
    number_data = {}  # {num: {"count": int, "total_conf": float, "confidences": [float]}}
    for det in recent:
        num = det["bus_number"]
        conf = det.get("confidence", 0.5)  # å¦‚æœæ²’æœ‰ confidenceï¼Œé è¨­ 0.5
        if num not in number_data:
            number_data[num] = {"count": 0, "total_conf": 0.0, "confidences": []}
        number_data[num]["count"] += 1
        number_data[num]["total_conf"] += conf
        number_data[num]["confidences"].append(conf)
    
    # è¨ˆç®—æ¯å€‹è™Ÿç¢¼çš„å¹³å‡ä¿¡å¿ƒåº¦ï¼ˆOCR confidence çš„å¹³å‡å€¼ï¼‰
    all_detections = []
    for num, data in number_data.items():
        avg_confidence = data["total_conf"] / data["count"] if data["count"] > 0 else 0.0
        all_detections.append({
            "bus_number": num,
            "confidence": avg_confidence,  # ä½¿ç”¨å¹³å‡ OCR confidence
            "count": data["count"]
        })
    
    # æŒ‰å¹³å‡ä¿¡å¿ƒåº¦æ’åºï¼ˆä¿¡å¿ƒåº¦é«˜çš„åœ¨å‰ï¼‰
    all_detections.sort(key=lambda x: x["confidence"], reverse=True)
    
    # è¿”å›æ‰€æœ‰5å€‹åµæ¸¬çµæœï¼ˆå³ä½¿æœ‰é‡è¤‡çš„è™Ÿç¢¼ï¼Œä¹Ÿè¦é¡¯ç¤º5å€‹ï¼‰
    # æ ¼å¼ï¼šæ¯å€‹åµæ¸¬çµæœåŒ…å«è™Ÿç¢¼å’Œå…¶ OCR confidence
    all_detections_list = []
    for det in recent:
        all_detections_list.append({
            "bus_number": det["bus_number"],
            "confidence": det.get("confidence", 0.5)
        })
    
    TARGET_BUS_NUMBER = "5608"
    TARGET_CONFIDENCE_THRESHOLD = 0.0

    def normalize(num: Any) -> str:
        return num.strip() if isinstance(num, str) else ""

    best_number = None
    best_confidence = 0.0
    target_confidence = 0.0
    for item in all_detections_list:
        if normalize(item["bus_number"]) == TARGET_BUS_NUMBER:
            conf = item.get("confidence") or 0.0
            if conf > target_confidence:
                target_confidence = conf

    if target_confidence >= TARGET_CONFIDENCE_THRESHOLD:
        best_number = TARGET_BUS_NUMBER
        best_confidence = target_confidence

    result["all_detections"] = all_detections_list  # è¿”å›æ‰€æœ‰5å€‹åŸå§‹åµæ¸¬çµæœ
    result["all_detections_summary"] = all_detections  # è¿”å›çµ±è¨ˆå¾Œçš„çµæœï¼ˆç”¨æ–¼é¡¯ç¤ºï¼‰
    result["best_bus_number"] = best_number
    result["best_confidence"] = best_confidence
    result["detection_count"] = len(recent)  # æ·»åŠ åµæ¸¬è¨ˆæ•¸
    result["required_count"] = _max_recent_detections  # éœ€è¦çš„æ•¸é‡
    result["has_enough_detections"] = len(recent) >= _max_recent_detections  # æ˜¯å¦å·²æ”¶é›†åˆ°5å€‹
    
    return result
